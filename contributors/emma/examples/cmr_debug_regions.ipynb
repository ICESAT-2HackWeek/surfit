{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SlideRule CMR Debug\n",
    "A simple tool for checking CMR queries\n",
    "- Creates a leaflet map for creating regions of interest\n",
    "- Queries CMR for granules and granule polygons\n",
    "- Plots granule polygons on map\n",
    "- Retrieves and plots granule tracks on map\n",
    "\n",
    "### Jupyter and SlideRule\n",
    "[Jupyter widgets](https://ipywidgets.readthedocs.io) are used to set parameters for the SlideRule API.  \n",
    "\n",
    "Regions of interest for submitting to SlideRule are drawn on a [ipyleaflet](https://ipyleaflet.readthedocs.io) map.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import logging\n",
    "import posixpath\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import concurrent.futures\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import ipywidgets as widgets\n",
    "from shapely.geometry import LineString\n",
    "from sliderule import sliderule, icesat2, ipysliderule, earthdata, h5\n",
    "import sliderule.io\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# create logger\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set ICESat-2 Product \n",
    "\n",
    "- [ATL03: Global Geolocated Photon Data](https://nsidc.org/data/atl03)\n",
    "- [ATL06: Land Ice Height](https://nsidc.org/data/atl06)\n",
    "- [ATL08: Land and Vegetation Height](https://nsidc.org/data/atl08)\n",
    "\n",
    "### Interactive Mapping with Leaflet\n",
    "\n",
    "Interactive maps within the SlideRule python API are built upon [ipyleaflet](https://ipyleaflet.readthedocs.io).\n",
    "\n",
    "There are 3 projections available within SlideRule for mapping ([Global](https://epsg.io/3857), [North](https://epsg.io/5936) and [South](https://epsg.io/3031)).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure ICESat-2 API\n",
    "icesat2.init(\"slideruleearth.io\", loglevel=logging.WARNING)\n",
    "sliderule.get_version()\n",
    "\n",
    "# display widgets for setting ICESat-2 parameters\n",
    "# and the interactive map projection\n",
    "SRwidgets = ipysliderule.widgets()\n",
    "widgets.VBox([\n",
    "    SRwidgets.product,\n",
    "    SRwidgets.release,\n",
    "    SRwidgets.start_date,\n",
    "    SRwidgets.end_date,\n",
    "    SRwidgets.projection\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select regions of interest for querying CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create ipyleaflet map in specified projection\n",
    "m = ipysliderule.leaflet(SRwidgets.projection.value)\n",
    "m.map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and transmit CMR requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# for each region of interest\n",
    "granule_list = []\n",
    "granule_polygons = []\n",
    "for poly in m.regions:\n",
    "    # polygon from map\n",
    "    resources,metadata = earthdata.cmr(polygon=poly,\n",
    "        short_name=SRwidgets.product.value,\n",
    "        time_start=SRwidgets.time_start,\n",
    "        time_end=SRwidgets.time_end,\n",
    "        version=SRwidgets.release.value,\n",
    "        return_metadata=True)\n",
    "    # for each granule resource\n",
    "    for i,resource in enumerate(resources):\n",
    "        granule_list.append(resource)\n",
    "        granule_polygons.append(metadata[i].geometry)\n",
    "# print list of granules\n",
    "num_granules = len(granule_list)\n",
    "logging.info('Number of Granules: {0:d}'.format(num_granules))\n",
    "logging.debug(granule_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Granules to Plot on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "granule_select = widgets.SelectMultiple(\n",
    "    options=granule_list,\n",
    "    description='Granules:',\n",
    "    layout=widgets.Layout(width='35%', height='200px'),\n",
    "    disabled=False\n",
    ")\n",
    "display(granule_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add granule polygons to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "granule_indices = list(granule_select.index)\n",
    "cmap = iter(cm.viridis(np.linspace(0,1,len(granule_indices))))\n",
    "for g in granule_indices:\n",
    "    color = colors.to_hex(next(cmap))\n",
    "    geojson = ipysliderule.ipyleaflet.GeoJSON(\n",
    "        data=granule_polygons[g].__geo_interface__,\n",
    "        style=dict(\n",
    "            color=color,\n",
    "            fill_color=color,\n",
    "            opacity=0.8,\n",
    "            weight=1,\n",
    "        )\n",
    "    )\n",
    "    m.map.add_layer(geojson)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Granules from NSIDC S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def s3_retrieve(granule, **kwargs):\n",
    "    # set default keyword arguments\n",
    "    kwargs.setdefault('asset','icesat2')\n",
    "    kwargs.setdefault('index_key','time')\n",
    "    kwargs.setdefault('polygon',None)\n",
    "    # regular expression operator for extracting information from files\n",
    "    rx = re.compile(r'(ATL\\d{2})(-\\d{2})?_(\\d{4})(\\d{2})(\\d{2})(\\d{2})'\n",
    "        r'(\\d{2})(\\d{2})_(\\d{4})(\\d{2})(\\d{2})_(\\d{3})_(\\d{2})(.*?).h5$')\n",
    "    # extract parameters from ICESat-2 granule\n",
    "    PRD,HEM,YY,MM,DD,HH,MN,SS,TRK,CYCL,GRN,RL,VRS,AUX=rx.findall(granule).pop()\n",
    "    # variables of interest\n",
    "    if (PRD == 'ATL03'):\n",
    "        segment_group = \"geolocation\"\n",
    "        segment_key = 'segment_id'\n",
    "        lon_key = 'reference_photon_lon'\n",
    "        lat_key = 'reference_photon_lat'\n",
    "        vnames = ['segment_id','delta_time','reference_photon_lat',\n",
    "            'reference_photon_lon']\n",
    "    elif (PRD == 'ATL06'):\n",
    "        segment_group = \"land_ice_segments\"\n",
    "        segment_key = 'segment_id'\n",
    "        lon_key = 'longitude'\n",
    "        lat_key = 'latitude'\n",
    "        vnames = ['segment_id','delta_time','latitude','longitude']\n",
    "    elif (PRD == 'ATL08'):\n",
    "        segment_group = \"land_segments\"\n",
    "        segment_key = 'segment_id_beg'\n",
    "        lon_key = 'longitude'\n",
    "        lat_key = 'latitude'\n",
    "        vnames = ['segment_id_beg','segment_id_end','delta_time',\n",
    "            'latitude','longitude']\n",
    "    # for each valid beam within the HDF5 file\n",
    "    frames = []\n",
    "    gt = dict(gt1l=10,gt1r=20,gt2l=30,gt2r=40,gt3l=50,gt3r=60)\n",
    "    atlas_sdp_epoch = np.datetime64('2018-01-01T00:00:00')\n",
    "    kwds = dict(startrow=0,numrows=-1)\n",
    "    for gtx in ['gt1l','gt1r','gt2l','gt2r','gt3l','gt3r']:\n",
    "        geodatasets = [dict(dataset=f'{gtx}/{segment_group}/{v}',**kwds) for v in vnames]\n",
    "        try:\n",
    "            # get datasets from s3\n",
    "            hidatasets = h5.h5p(geodatasets, granule, kwargs['asset'])\n",
    "            # copy to new \"flattened\" dictionary\n",
    "            data = {posixpath.basename(key):var for key,var in hidatasets.items()}\n",
    "            # Generate Time Column\n",
    "            delta_time = (data['delta_time']*1e9).astype('timedelta64[ns]')\n",
    "            data['time'] = gpd.pd.to_datetime(atlas_sdp_epoch + delta_time)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            # copy filename parameters\n",
    "            data['rgt'] = [int(TRK)]*len(data['delta_time'])\n",
    "            data['cycle'] = [int(CYCL)]*len(data['delta_time'])\n",
    "            data['gt'] = [gt[gtx]]*len(data['delta_time'])\n",
    "            # pandas dataframe from compiled dictionary\n",
    "            frames.append(gpd.pd.DataFrame.from_dict(data))\n",
    "    # concatenate pandas dataframe\n",
    "    try:\n",
    "        df = gpd.pd.concat(frames)\n",
    "    except:\n",
    "        return sliderule.emptyframe()\n",
    "    # convert to a GeoDataFrame\n",
    "    geometry = gpd.points_from_xy(df[lon_key], df[lat_key])\n",
    "    gdf = gpd.GeoDataFrame(df.drop(columns=[lon_key,lat_key]),\n",
    "        geometry=geometry,crs='EPSG:4326')\n",
    "    # create global track variable\n",
    "    track = 6*(gdf['rgt']-1) + (gdf['gt']/10)\n",
    "    gdf = gdf.assign(track=track)\n",
    "    # calculate global reference point\n",
    "    global_ref_pt = 6*1387*gdf[segment_key] + track\n",
    "    gdf = gdf.assign(global_ref_pt=global_ref_pt)\n",
    "    # sort values for reproducible output despite async processing\n",
    "    gdf.set_index(kwargs['index_key'], inplace=True)\n",
    "    gdf.sort_index(inplace=True)\n",
    "    # remove duplicate points\n",
    "    gdf = gdf[~gdf.index.duplicated()]\n",
    "    # intersect with geometry in projected reference system\n",
    "    if kwargs['polygon'] is not None:\n",
    "        gdf = gpd.overlay(gdf.to_crs(kwargs['polygon'].crs),\n",
    "            kwargs['polygon'], how='intersection')\n",
    "    # convert back to original coordinate reference system\n",
    "    return gdf.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = []\n",
    "# granule resources for selected segments\n",
    "perf_start = time.perf_counter()\n",
    "gdf = sliderule.emptyframe()\n",
    "num_servers, _ = sliderule.update_available_servers()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_servers) as executor:\n",
    "    futures = [executor.submit(s3_retrieve, granule_list[g]) for g in granule_indices]\n",
    "    # Wait for Results\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        # append to dataframe\n",
    "        results.append(future.result())\n",
    "gdf = gpd.pd.concat(results)\n",
    "# Display Statistics\n",
    "print(\"Reference Ground Tracks: {}\".format(gdf[\"rgt\"].unique()))\n",
    "print(\"Cycles: {}\".format(gdf[\"cycle\"].unique()))\n",
    "print(\"Received {} segments\".format(gdf.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Granule Track Polylines to Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix int columns that were converted in objects\n",
    "fixed = gdf.drop(columns=['geometry'])\n",
    "for column in fixed.select_dtypes(include='object').columns:\n",
    "    fixed[column] = fixed[column].astype(\"int32\")\n",
    "fixed = gpd.GeoDataFrame(fixed,geometry=gdf.geometry,crs='EPSG:4326')\n",
    "# convert from points to linestrings grouping by track\n",
    "grouped = fixed.groupby(['track'])['geometry'].apply(\n",
    "    lambda x: LineString(x.tolist()) if x.size > 1 else x.tolist())\n",
    "geodata = ipysliderule.ipyleaflet.GeoData(geo_dataframe=gpd.GeoDataFrame(grouped),\n",
    "    style={'color': 'black', 'opacity':1, 'weight':0.1})\n",
    "m.map.add_layer(geodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
